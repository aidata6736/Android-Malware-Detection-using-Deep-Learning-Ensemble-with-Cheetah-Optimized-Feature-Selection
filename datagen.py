import pandas as pd
from sklearn.preprocessing import LabelEncoder
import joblib
import numpy as np
from sklearn.model_selection import train_test_split
from save_load import save


def datagen():

    data = pd.read_csv('Dataset/Android_Malware.csv')

    data = data.drop(
        columns=['Unnamed: 0', 'Flow ID', ' Source IP', ' Source Port', ' Destination IP', ' Destination Port',
                 ' Protocol',
                 ' Timestamp', ' min_seg_size_forward', ' Fwd Header Length.1', ' Fwd Header Length',
                 ' Bwd Header Length'])

    # Data Cleaning
    data.dropna(inplace=True)

    Label = data['Label']
    data = data.drop('Label', axis=1)
    Lab_encoder = LabelEncoder()
    labels = Lab_encoder.fit_transform(Label)
    joblib.dump(Lab_encoder, 'Saved Data/label_encoder.joblib')
    save('labels', labels)

    data_numeric = data.apply(pd.to_numeric, errors='coerce')
    # feature extraction
    # statistical features  - Central Tendency
    mean = data_numeric.mean(axis=1)
    median = data_numeric.median(axis=1)
    mode = data_numeric.mode(axis=1)
    # spread
    std_dev = data_numeric.std(axis=1)
    variance = data_numeric.var(axis=1)
    # Identify and handle outliers using Interquartile Range (IQR)
    q1 = data_numeric.quantile(0.25, axis=1)
    q3 = data_numeric.quantile(0.75, axis=1)
    iqr = q3 - q1

    skewness = data_numeric.skew(axis=1)
    kurtosis = data_numeric.kurt(axis=1)

    # Flow based features
    flow_duration = data_numeric[' Flow Duration']
    flow_bytes = data_numeric['Flow Bytes/s']
    flow_packets = data_numeric[' Flow Packets/s']
    flow_mean = data_numeric[' Flow IAT Mean']
    flow_std = data_numeric[' Flow IAT Std']
    flow_max = data_numeric[' Flow IAT Max']
    flow_min = data_numeric[' Flow IAT Min']

    # Packet based feature
    total_fwd_packets = data_numeric[' Total Fwd Packets']
    total_bcwd_packets = data_numeric[' Total Backward Packets']
    total_len_of_fwd_pacts = data_numeric['Total Length of Fwd Packets']
    total_len_of_bwd_pacts = data_numeric[' Total Length of Bwd Packets']
    fwd_packs_len_max = data_numeric[' Fwd Packet Length Max']
    fwd_packs_len_min = data_numeric[' Fwd Packet Length Min']
    fwd_packs_len_mean = data_numeric[' Fwd Packet Length Mean']
    fwd_packs_len_std = data_numeric[' Fwd Packet Length Std']
    bwd_packs_len_max = data_numeric['Bwd Packet Length Max']
    bwd_packs_len_min = data_numeric[' Bwd Packet Length Min']
    bwd_packs_len_mean = data_numeric[' Bwd Packet Length Mean']
    bwd_packs_len_std = data_numeric[' Bwd Packet Length Std']
    fwd_packets = data_numeric['Fwd Packets/s']
    bwd_packets = data_numeric[' Bwd Packets/s']
    min_packet_len = data_numeric[' Min Packet Length']
    max_packet_len = data_numeric[' Max Packet Length']
    packet_len_mean = data_numeric[' Packet Length Mean']
    packet_len_std = data_numeric[' Packet Length Std']
    packet_len_variance = data_numeric[' Packet Length Variance']

    combined_features = pd.DataFrame(
        np.column_stack([mean, median, mode, std_dev, variance, iqr, skewness, kurtosis, flow_duration, flow_bytes,
                         flow_packets, flow_mean, flow_std, flow_max, flow_min, total_fwd_packets, total_bcwd_packets,
                         total_len_of_fwd_pacts, total_len_of_bwd_pacts, fwd_packs_len_max, fwd_packs_len_min,
                         fwd_packs_len_mean,
                         fwd_packs_len_std, bwd_packs_len_max, bwd_packs_len_min, bwd_packs_len_mean, bwd_packs_len_std,
                         fwd_packets, bwd_packets, min_packet_len, max_packet_len, packet_len_mean, packet_len_std,
                         packet_len_variance]))

    features = np.array(combined_features)

    # Absolute
    features = abs(features)

    # Normalization
    features = features / np.max(features, axis=0)

    # Nan to Num conversion
    features = np.nan_to_num(features)
    save('features', features)

    train_sizes = [0.6, 0.7, 0.8]
    for train_size in train_sizes:
        x_train, x_test, y_train, y_test = train_test_split(features, labels, train_size=train_size)
        save('x_train_' + str(int(train_size * 100)), x_train)
        save('x_test_' + str(int(train_size * 100)), x_test)
        save('y_train_' + str(int(train_size * 100)), y_train)
        save('y_test_' + str(int(train_size * 100)), y_test)
